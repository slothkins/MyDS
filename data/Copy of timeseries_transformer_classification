{"cells":[{"cell_type":"markdown","metadata":{"id":"_guIKODvWF0x"},"source":["# Timeseries classification with a Transformer model\n","\n","**Author:** [Theodoros Ntakouris](https://github.com/ntakouris)\u003cbr\u003e\n","**Date created:** 2021/06/25\u003cbr\u003e\n","**Last modified:** 2021/08/05\u003cbr\u003e\n","**Description:** This notebook demonstrates how to do timeseries classification using a Transformer model."]},{"cell_type":"markdown","metadata":{"id":"7yljr8ybWF00"},"source":["## Introduction\n","\n","This is the Transformer architecture from\n","[Attention Is All You Need](https://arxiv.org/abs/1706.03762),\n","applied to timeseries instead of natural language.\n","\n","This example requires TensorFlow 2.4 or higher.\n","\n","## Load the dataset\n","\n","We are going to use the same dataset and preprocessing as the\n","[TimeSeries Classification from Scratch](https://keras.io/examples/timeseries/timeseries_classification_from_scratch)\n","example."]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":1589,"status":"ok","timestamp":1664541698472,"user":{"displayName":"Nicolas Atkins","userId":"18408449888896392982"},"user_tz":-60},"id":"PhnsCzE5WF00"},"outputs":[],"source":["import numpy as np\n","\n","\n","def readucr(filename):\n","    data = np.loadtxt(filename, delimiter=\"\\t\")\n","    y = data[:, 0]\n","    x = data[:, 1:]\n","    return x, y.astype(int)\n","\n","\n","root_url = \"https://raw.githubusercontent.com/hfawaz/cd-diagram/master/FordA/\"\n","\n","x_train, y_train = readucr(root_url + \"FordA_TRAIN.tsv\")\n","x_test, y_test = readucr(root_url + \"FordA_TEST.tsv\")\n","\n","x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))\n","x_test = x_test.reshape((x_test.shape[0], x_test.shape[1], 1))\n","\n","n_classes = len(np.unique(y_train))\n","\n","idx = np.random.permutation(len(x_train))\n","x_train = x_train[idx]\n","y_train = y_train[idx]\n","\n","y_train[y_train == -1] = 0\n","y_test[y_test == -1] = 0"]},{"cell_type":"markdown","metadata":{"id":"X1w4U8KyWF01"},"source":["## Build the model\n","\n","Our model processes a tensor of shape `(batch size, sequence length, features)`,\n","where `sequence length` is the number of time steps and `features` is each input\n","timeseries.\n","\n","You can replace your classification RNN layers with this one: the\n","inputs are fully compatible!"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":3354,"status":"ok","timestamp":1664541720177,"user":{"displayName":"Nicolas Atkins","userId":"18408449888896392982"},"user_tz":-60},"id":"AenZ1N5eWF01"},"outputs":[],"source":["from tensorflow import keras\n","from tensorflow.keras import layers"]},{"cell_type":"markdown","metadata":{"id":"-WZxltUcWF02"},"source":["We include residual connections, layer normalization, and dropout.\n","The resulting layer can be stacked multiple times.\n","\n","The projection layers are implemented through `keras.layers.Conv1D`."]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":549,"status":"ok","timestamp":1664541817069,"user":{"displayName":"Nicolas Atkins","userId":"18408449888896392982"},"user_tz":-60},"id":"liJUB2MeWF02"},"outputs":[],"source":["\n","def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n","    # Normalization and Attention\n","    x = layers.LayerNormalization(epsilon=1e-6)(inputs)\n","    x = layers.MultiHeadAttention(\n","        key_dim=head_size, num_heads=num_heads, dropout=dropout\n","    )(x, x)\n","    x = layers.Dropout(dropout)(x)\n","    res = x + inputs\n","\n","    # Feed Forward Part\n","    x = layers.LayerNormalization(epsilon=1e-6)(res)\n","    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(x)\n","    x = layers.Dropout(dropout)(x)\n","    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n","    return x + res\n"]},{"cell_type":"markdown","metadata":{"id":"y_3SCCmdWF03"},"source":["The main part of our model is now complete. We can stack multiple of those\n","`transformer_encoder` blocks and we can also proceed to add the final\n","Multi-Layer Perceptron classification head. Apart from a stack of `Dense`\n","layers, we need to reduce the output tensor of the `TransformerEncoder` part of\n","our model down to a vector of features for each data point in the current\n","batch. A common way to achieve this is to use a pooling layer. For\n","this example, a `GlobalAveragePooling1D` layer is sufficient."]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":372,"status":"ok","timestamp":1664541843416,"user":{"displayName":"Nicolas Atkins","userId":"18408449888896392982"},"user_tz":-60},"id":"wkTdcwK4WF03"},"outputs":[],"source":["\n","def build_model(\n","    input_shape,\n","    head_size,\n","    num_heads,\n","    ff_dim,\n","    num_transformer_blocks,\n","    mlp_units,\n","    dropout=0,\n","    mlp_dropout=0,\n","):\n","    inputs = keras.Input(shape=input_shape)\n","    x = inputs\n","    for _ in range(num_transformer_blocks):\n","        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n","\n","    x = layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x)\n","    for dim in mlp_units:\n","        x = layers.Dense(dim, activation=\"relu\")(x)\n","        x = layers.Dropout(mlp_dropout)(x)\n","    outputs = layers.Dense(n_classes, activation=\"softmax\")(x)\n","    return keras.Model(inputs, outputs)\n"]},{"cell_type":"markdown","metadata":{"id":"3k5dYS12WF03"},"source":["## Train and evaluate"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"nAkPZcYhWF04"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_1 (InputLayer)           [(None, 500, 1)]     0           []                               \n","                                                                                                  \n"," layer_normalization (LayerNorm  (None, 500, 1)      2           ['input_1[0][0]']                \n"," alization)                                                                                       \n","                                                                                                  \n"," multi_head_attention (MultiHea  (None, 500, 1)      7169        ['layer_normalization[0][0]',    \n"," dAttention)                                                      'layer_normalization[0][0]']    \n","                                                                                                  \n"," dropout (Dropout)              (None, 500, 1)       0           ['multi_head_attention[0][0]']   \n","                                                                                                  \n"," tf.__operators__.add (TFOpLamb  (None, 500, 1)      0           ['dropout[0][0]',                \n"," da)                                                              'input_1[0][0]']                \n","                                                                                                  \n"," layer_normalization_1 (LayerNo  (None, 500, 1)      2           ['tf.__operators__.add[0][0]']   \n"," rmalization)                                                                                     \n","                                                                                                  \n"," conv1d (Conv1D)                (None, 500, 4)       8           ['layer_normalization_1[0][0]']  \n","                                                                                                  \n"," dropout_1 (Dropout)            (None, 500, 4)       0           ['conv1d[0][0]']                 \n","                                                                                                  \n"," conv1d_1 (Conv1D)              (None, 500, 1)       5           ['dropout_1[0][0]']              \n","                                                                                                  \n"," tf.__operators__.add_1 (TFOpLa  (None, 500, 1)      0           ['conv1d_1[0][0]',               \n"," mbda)                                                            'tf.__operators__.add[0][0]']   \n","                                                                                                  \n"," layer_normalization_2 (LayerNo  (None, 500, 1)      2           ['tf.__operators__.add_1[0][0]'] \n"," rmalization)                                                                                     \n","                                                                                                  \n"," multi_head_attention_1 (MultiH  (None, 500, 1)      7169        ['layer_normalization_2[0][0]',  \n"," eadAttention)                                                    'layer_normalization_2[0][0]']  \n","                                                                                                  \n"," dropout_2 (Dropout)            (None, 500, 1)       0           ['multi_head_attention_1[0][0]'] \n","                                                                                                  \n"," tf.__operators__.add_2 (TFOpLa  (None, 500, 1)      0           ['dropout_2[0][0]',              \n"," mbda)                                                            'tf.__operators__.add_1[0][0]'] \n","                                                                                                  \n"," layer_normalization_3 (LayerNo  (None, 500, 1)      2           ['tf.__operators__.add_2[0][0]'] \n"," rmalization)                                                                                     \n","                                                                                                  \n"," conv1d_2 (Conv1D)              (None, 500, 4)       8           ['layer_normalization_3[0][0]']  \n","                                                                                                  \n"," dropout_3 (Dropout)            (None, 500, 4)       0           ['conv1d_2[0][0]']               \n","                                                                                                  \n"," conv1d_3 (Conv1D)              (None, 500, 1)       5           ['dropout_3[0][0]']              \n","                                                                                                  \n"," tf.__operators__.add_3 (TFOpLa  (None, 500, 1)      0           ['conv1d_3[0][0]',               \n"," mbda)                                                            'tf.__operators__.add_2[0][0]'] \n","                                                                                                  \n"," layer_normalization_4 (LayerNo  (None, 500, 1)      2           ['tf.__operators__.add_3[0][0]'] \n"," rmalization)                                                                                     \n","                                                                                                  \n"," multi_head_attention_2 (MultiH  (None, 500, 1)      7169        ['layer_normalization_4[0][0]',  \n"," eadAttention)                                                    'layer_normalization_4[0][0]']  \n","                                                                                                  \n"," dropout_4 (Dropout)            (None, 500, 1)       0           ['multi_head_attention_2[0][0]'] \n","                                                                                                  \n"," tf.__operators__.add_4 (TFOpLa  (None, 500, 1)      0           ['dropout_4[0][0]',              \n"," mbda)                                                            'tf.__operators__.add_3[0][0]'] \n","                                                                                                  \n"," layer_normalization_5 (LayerNo  (None, 500, 1)      2           ['tf.__operators__.add_4[0][0]'] \n"," rmalization)                                                                                     \n","                                                                                                  \n"," conv1d_4 (Conv1D)              (None, 500, 4)       8           ['layer_normalization_5[0][0]']  \n","                                                                                                  \n"," dropout_5 (Dropout)            (None, 500, 4)       0           ['conv1d_4[0][0]']               \n","                                                                                                  \n"," conv1d_5 (Conv1D)              (None, 500, 1)       5           ['dropout_5[0][0]']              \n","                                                                                                  \n"," tf.__operators__.add_5 (TFOpLa  (None, 500, 1)      0           ['conv1d_5[0][0]',               \n"," mbda)                                                            'tf.__operators__.add_4[0][0]'] \n","                                                                                                  \n"," layer_normalization_6 (LayerNo  (None, 500, 1)      2           ['tf.__operators__.add_5[0][0]'] \n"," rmalization)                                                                                     \n","                                                                                                  \n"," multi_head_attention_3 (MultiH  (None, 500, 1)      7169        ['layer_normalization_6[0][0]',  \n"," eadAttention)                                                    'layer_normalization_6[0][0]']  \n","                                                                                                  \n"," dropout_6 (Dropout)            (None, 500, 1)       0           ['multi_head_attention_3[0][0]'] \n","                                                                                                  \n"," tf.__operators__.add_6 (TFOpLa  (None, 500, 1)      0           ['dropout_6[0][0]',              \n"," mbda)                                                            'tf.__operators__.add_5[0][0]'] \n","                                                                                                  \n"," layer_normalization_7 (LayerNo  (None, 500, 1)      2           ['tf.__operators__.add_6[0][0]'] \n"," rmalization)                                                                                     \n","                                                                                                  \n"," conv1d_6 (Conv1D)              (None, 500, 4)       8           ['layer_normalization_7[0][0]']  \n","                                                                                                  \n"," dropout_7 (Dropout)            (None, 500, 4)       0           ['conv1d_6[0][0]']               \n","                                                                                                  \n"," conv1d_7 (Conv1D)              (None, 500, 1)       5           ['dropout_7[0][0]']              \n","                                                                                                  \n"," tf.__operators__.add_7 (TFOpLa  (None, 500, 1)      0           ['conv1d_7[0][0]',               \n"," mbda)                                                            'tf.__operators__.add_6[0][0]'] \n","                                                                                                  \n"," global_average_pooling1d (Glob  (None, 500)         0           ['tf.__operators__.add_7[0][0]'] \n"," alAveragePooling1D)                                                                              \n","                                                                                                  \n"," dense (Dense)                  (None, 128)          64128       ['global_average_pooling1d[0][0]'\n","                                                                 ]                                \n","                                                                                                  \n"," dropout_8 (Dropout)            (None, 128)          0           ['dense[0][0]']                  \n","                                                                                                  \n"," dense_1 (Dense)                (None, 2)            258         ['dropout_8[0][0]']              \n","                                                                                                  \n","==================================================================================================\n","Total params: 93,130\n","Trainable params: 93,130\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","Epoch 1/200\n","45/45 [==============================] - 1271s 28s/step - loss: 1.0316 - sparse_categorical_accuracy: 0.5076 - val_loss: 0.7608 - val_sparse_categorical_accuracy: 0.5645\n","Epoch 2/200\n","45/45 [==============================] - 1302s 29s/step - loss: 0.8523 - sparse_categorical_accuracy: 0.5549 - val_loss: 0.6732 - val_sparse_categorical_accuracy: 0.6352\n","Epoch 3/200\n","45/45 [==============================] - 1278s 28s/step - loss: 0.7789 - sparse_categorical_accuracy: 0.5781 - val_loss: 0.6198 - val_sparse_categorical_accuracy: 0.6810\n","Epoch 4/200\n","45/45 [==============================] - 1275s 28s/step - loss: 0.7275 - sparse_categorical_accuracy: 0.6122 - val_loss: 0.5917 - val_sparse_categorical_accuracy: 0.6727\n","Epoch 5/200\n","45/45 [==============================] - 1275s 28s/step - loss: 0.6683 - sparse_categorical_accuracy: 0.6476 - val_loss: 0.5748 - val_sparse_categorical_accuracy: 0.7087\n","Epoch 6/200\n","30/45 [===================\u003e..........] - ETA: 6:31 - loss: 0.6356 - sparse_categorical_accuracy: 0.6661"]}],"source":["input_shape = x_train.shape[1:]\n","\n","model = build_model(\n","    input_shape,\n","    head_size=256,\n","    num_heads=4,\n","    ff_dim=4,\n","    num_transformer_blocks=4,\n","    mlp_units=[128],\n","    mlp_dropout=0.4,\n","    dropout=0.25,\n",")\n","\n","model.compile(\n","    loss=\"sparse_categorical_crossentropy\",\n","    optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n","    metrics=[\"sparse_categorical_accuracy\"],\n",")\n","model.summary()\n","\n","callbacks = [keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)]\n","\n","model.fit(\n","    x_train,\n","    y_train,\n","    validation_split=0.2,\n","    epochs=200,\n","    batch_size=64,\n","    callbacks=callbacks,\n",")\n","\n","model.evaluate(x_test, y_test, verbose=1)"]},{"cell_type":"markdown","metadata":{"id":"4vlGVpgLWF04"},"source":["## Conclusions\n","\n","In about 110-120 epochs (25s each on Colab), the model reaches a training\n","accuracy of ~0.95, validation accuracy of ~84 and a testing\n","accuracy of ~85, without hyperparameter tuning. And that is for a model\n","with less than 100k parameters. Of course, parameter count and accuracy could be\n","improved by a hyperparameter search and a more sophisticated learning rate\n","schedule, or a different optimizer.\n","\n","You can use the trained model hosted on [Hugging Face Hub](https://huggingface.co/keras-io/timeseries_transformer_classification) and try the demo on [Hugging Face Spaces](https://huggingface.co/spaces/keras-io/timeseries_transformer_classification)."]}],"metadata":{"colab":{"collapsed_sections":[],"name":"","provenance":[{"file_id":"https://github.com/keras-team/keras-io/blob/master/examples/timeseries/ipynb/timeseries_classification_transformer.ipynb","timestamp":1664540515744}],"toc_visible":true,"version":""},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"}},"nbformat":4,"nbformat_minor":0}